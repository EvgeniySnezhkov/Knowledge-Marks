# Generative Tools 
---
Autoencoders: [https://colab.research.google.com/github/zaidalyafeai/Notebooks/blob/master/AutoEncoders.ipynb](https://colab.research.google.com/github/zaidalyafeai/Notebooks/blob/master/AutoEncoders.ipynb)

  

Colorization:

[https://demos.algorithmia.com/colorize-photos](https://demos.algorithmia.com/colorize-photos)

[https://www.myheritage.co.il/incolor](https://www.myheritage.co.il/incolor)

[https://colab.research.google.com/github/jantic/DeOldify/blob/master/ImageColorizerColab.ipynb](https://colab.research.google.com/github/jantic/DeOldify/blob/master/ImageColorizerColab.ipynb)

[https://colab.research.google.com/github/jantic/DeOldify/blob/master/ImageColorizerColabStable.ipynb](https://colab.research.google.com/github/jantic/DeOldify/blob/master/ImageColorizerColabStable.ipynb)

[https://colab.research.google.com/github/jantic/DeOldify/blob/master/VideoColorizerColab.ipynb](https://colab.research.google.com/github/jantic/DeOldify/blob/master/VideoColorizerColab.ipynb)

[https://colab.research.google.com/drive/1Y1XTlTdUG-2LzrH1Vnr_osg9BQavfYsz](https://colab.research.google.com/drive/1Y1XTlTdUG-2LzrH1Vnr_osg9BQavfYsz) (exemplar based)

[https://github.com/msracver/Deep-Exemplar-based-Colorization](https://github.com/msracver/Deep-Exemplar-based-Colorization) (window .exe, exemplar based)

Review of more: [https://www.youtube.com/watch?v=mUXpxxyThr8](https://www.youtube.com/watch?v=mUXpxxyThr8&feature=youtu.be)

[https://colab.research.google.com/github/ericsujw/InstColorization/blob/master/InstColorization.ipynb](https://colab.research.google.com/github/ericsujw/InstColorization/blob/master/InstColorization.ipynb)

[https://colab.research.google.com/github/pvitoria/ChromaGAN/blob/master/DemoChromaGAN.ipynb](https://colab.research.google.com/github/pvitoria/ChromaGAN/blob/master/DemoChromaGAN.ipynb)

  

Jukebox:

[https://colab.research.google.com/github/openai/jukebox/blob/master/jukebox/Interacting_with_Jukebox.ipynb](https://colab.research.google.com/github/openai/jukebox/blob/master/jukebox/Interacting_with_Jukebox.ipynb)

  
  

Super-resolution and image enhancement:

[https://letsenhance.io](https://letsenhance.io)

[https://bigjpg.com/](https://bigjpg.com/)

[https://colab.research.google.com/github/idealo/image-super-resolution/blob/master/notebooks/ISR_Prediction_Tutorial.ipynb](https://colab.research.google.com/github/idealo/image-super-resolution/blob/master/notebooks/ISR_Prediction_Tutorial.ipynb)

(video!) [https://colab.research.google.com/drive/1dxYc6BBtUwOaIl6YHgHsoORel-8nhJNP](https://colab.research.google.com/drive/1dxYc6BBtUwOaIl6YHgHsoORel-8nhJNP)

[https://colab.research.google.com/github/tg-bomze/DFDNet/blob/whole/DFDNet_Colab.ipynb](https://colab.research.google.com/github/tg-bomze/DFDNet/blob/whole/DFDNet_Colab.ipynb)

[ISR Prediction Tutorial.ipynb - Colaboratory](https://colab.research.google.com/github/idealo/image-super-resolution/blob/master/notebooks/ISR_Prediction_Tutorial.ipynb)[https://colab.research.google.com/github/tg-bomze/DFDNet/blob/whole/DFDNet_Colab_Eng.ipynb](https://colab.research.google.com/github/tg-bomze/DFDNet/blob/whole/DFDNet_Colab_Eng.ipynb)

[https://colab.research.google.com/github/tg-bomze/DFDNet/blob/whole/DFDNet_Colab_for_DeepFakers.ipynb](https://colab.research.google.com/github/tg-bomze/DFDNet/blob/whole/DFDNet_Colab_for_DeepFakers.ipynb)

  
  

Blind face restoration (and colorization)

[https://colab.research.google.com/drive/1sVsoBd9AjckIXThgtZhGrHRfFI6UUYOo](https://colab.research.google.com/drive/1sVsoBd9AjckIXThgtZhGrHRfFI6UUYOo)

[https://colab.research.google.com/github/bycloudai/GPEN-colab/blob/main/GPEN.ipynb](https://colab.research.google.com/github/bycloudai/GPEN-colab/blob/main/GPEN.ipynb)

  
  
  

Photo restoration:

[https://colab.research.google.com/drive/1NEm6AsybIiC5TwTU_4DqDkQO0nFRB-uA](https://colab.research.google.com/drive/1NEm6AsybIiC5TwTU_4DqDkQO0nFRB-uA?usp=sharing#scrollTo=LMnje_NWj24x)

  

Destroy and recover : [https://colab.research.google.com/github/tg-bomze/collection-of-notebooks/blob/master/Destroy_n_Recover.ipynb](https://colab.research.google.com/github/tg-bomze/collection-of-notebooks/blob/master/Destroy_n_Recover.ipynb)

  

Single shot denoising:

[https://colab.research.google.com/github/DmitryUlyanov/deep-image-prior/blob/master/denoising.ipynb](https://colab.research.google.com/github/DmitryUlyanov/deep-image-prior/blob/master/denoising.ipynb)

[https://colab.research.google.com/github/czbiohub/noise2self/blob/master/notebooks/Single-Shot Denoising.ipynb](https://colab.research.google.com/github/czbiohub/noise2self/blob/master/notebooks/Single-Shot%20Denoising.ipynb)

  

deepSVG: [https://github.com/alexandre01/deepsvg/blob/master/notebooks](https://github.com/alexandre01/deepsvg/blob/master/notebooks)

  
  

Inpainting: [https://www.nvidia.com/research/inpainting/](https://www.nvidia.com/research/inpainting/)

  

Image completion: [https://colab.research.google.com/github/google/trax/blob/master/trax/models/reformer/image_generation.ipynb](https://colab.research.google.com/github/google/trax/blob/master/trax/models/reformer/image_generation.ipynb) (reformer)

  

Image generation with gradient origin networks:

[https://github.com/cwkx/GON](https://github.com/cwkx/GON)

  

Image generation with AI2 X-LXMERT

[https://vision-explorer.allenai.org/text_to_image_generation](https://vision-explorer.allenai.org/text_to_image_generation)

  
  

Body segmentation: [https://storage.googleapis.com/tfjs-models/demos/body-pix/index.html](https://storage.googleapis.com/tfjs-models/demos/body-pix/index.html)

  

Deep dream:

[https://deepdreamgenerator.com](https://deepdreamgenerator.com)

[https://colab.research.google.com/drive/1WWpJ3gzUOBThdXwqsrF0b3uCmr6o0Q4G](https://colab.research.google.com/drive/1WWpJ3gzUOBThdXwqsrF0b3uCmr6o0Q4G)

[https://colab.research.google.com/github/tensorflow/lucid/blob/master/notebooks/misc/feature_inversion_caricatures.ipynb](https://colab.research.google.com/github/tensorflow/lucid/blob/master/notebooks/misc/feature_inversion_caricatures.ipynb) (lucid)

[https://colab.research.google.com/github/Mayukhdeb/torch-dreams-notebooks/blob/main/docs_notebooks/hello_torch_dreams.ipynb](https://colab.research.google.com/github/Mayukhdeb/torch-dreams-notebooks/blob/main/docs_notebooks/hello_torch_dreams.ipynb)

[https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/generative/deepdream.ipynb](https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/generative/deepdream.ipynb)

[https://colab.research.google.com/github/artistic-ai/deepdream-tensorflow/blob/master/deepdream.ipynb](https://colab.research.google.com/github/artistic-ai/deepdream-tensorflow/blob/master/deepdream.ipynb)

  
  

Style Transfer:

[https://reiinakano.github.io/arbitrary-image-stylization-tfjs/](https://reiinakano.github.io/arbitrary-image-stylization-tfjs/)

[https://deepdreamgenerator.com](https://deepdreamgenerator.com)

[https://dreamscopeapp.com/](https://dreamscopeapp.com/)

[https://deepart.io/](https://deepart.io/)

[https://www.instapainting.com/assets](https://www.instapainting.com/assets)

[http://ostagram.me/static_pages/lenta?last_days=1000&locale=en](http://ostagram.me/static_pages/lenta?last_days=1000&locale=en)

[https://zaidalyafeai.github.io/WST/](https://zaidalyafeai.github.io/WST/)

[https://colab.research.google.com/drive/1aAUevMar82TEIVZkTHvPnRiC1xpixrvA](https://colab.research.google.com/drive/1aAUevMar82TEIVZkTHvPnRiC1xpixrvA)

[https://github.com/EugenHotaj/nn-hallucinations/blob/master/style_transfer.ipynb](https://github.com/EugenHotaj/nn-hallucinations/blob/master/style_transfer.ipynb)

[https://colab.research.google.com/drive/1JshOp4J7bdIpvJZplZ--wwaisSBUx9tF](https://colab.research.google.com/drive/1JshOp4J7bdIpvJZplZ--wwaisSBUx9tF) (MUNIT)

  

Style harmonization:

[https://j.mp/deepharm](https://j.mp/deepharm) (deep painterly harmonization colab)

  

Cyclegan

[https://www.kaggle.com/amyjang/monet-cyclegan-tutorial](https://www.kaggle.com/amyjang/monet-cyclegan-tutorial)

  
  

StyleGAN:

[https://colab.research.google.com/gist/kylemcdonald/7920a7329518a54f59f2a237aca92529/stylegan.ipynb](https://colab.research.google.com/gist/kylemcdonald/7920a7329518a54f59f2a237aca92529/stylegan.ipynb)

[https://eyalgruss.com/smile](https://eyalgruss.com/smile)

[https://eyalgruss.com/smiley](https://eyalgruss.com/smiley)

[https://colab.research.google.com/drive/1cFKK0CBnev2BF8z9BOHxePk7E-f7TtUi](https://colab.research.google.com/drive/1cFKK0CBnev2BF8z9BOHxePk7E-f7TtUi)

[https://colab.research.google.com/github/pbaylies/stylegan-encoder/blob/master/StyleGAN_Encoder_Tutorial.ipynb](https://colab.research.google.com/github/pbaylies/stylegan-encoder/blob/master/StyleGAN_Encoder_Tutorial.ipynb)

[https://github.com/Norod/my-colab-experiments/blob/master/fun_with_stylegan.ipynb](https://github.com/Norod/my-colab-experiments/blob/master/fun_with_stylegan.ipynb)

[https://github.com/Norod/my-colab-experiments/blob/master/fun_with_stylegan2_ffhq.ipynb](https://github.com/Norod/my-colab-experiments/blob/master/fun_with_stylegan2_ffhq.ipynb)

[https://github.com/Puzer/stylegan-encoder](https://github.com/Puzer/stylegan-encoder)

[https://colab.research.google.com/github/ak9250/stylegan2/blob/master/stylegan2colab.ipynb](https://colab.research.google.com/github/ak9250/stylegan2/blob/master/stylegan2colab.ipynb)

[https://github.com/arfafax/StyleGAN2_experiments/blob/master/StyleGAN2%20Network%20Interpolation.ipynb](https://github.com/arfafax/StyleGAN2_experiments/blob/master/StyleGAN2%20Network%20Interpolation.ipynb)

[https://github.com/parthsuresh/stylegan2-colab/blob/master/StyleGAN2_Google_Colab.ipynb](https://github.com/parthsuresh/stylegan2-colab/blob/master/StyleGAN2_Google_Colab.ipynb)

[https://colab.research.google.com/github/Norod/my-colab-experiments/blob/master/fun_with_stylegan2_furries.ipynb](https://colab.research.google.com/github/Norod/my-colab-experiments/blob/master/fun_with_stylegan2_furries.ipynb) (truncation animation)

[https://colab.research.google.com/github/harskish/ganspace/blob/master/notebooks/Ganspace_colab.ipynb](https://colab.research.google.com/github/harskish/ganspace/blob/master/notebooks/Ganspace_colab.ipynb)

[https://colab.research.google.com/drive/1_LIu91bFGCeeLPnuT8A669BYbtz0nwFI](https://colab.research.google.com/drive/1_LIu91bFGCeeLPnuT8A669BYbtz0nwFI)

[https://github.com/dvschultz/ai/blob/master/StyleGAN2_AudioReactive.ipynb](https://github.com/dvschultz/ai/blob/master/StyleGAN2_AudioReactive.ipynb) (reactive audio!)

[https://colab.research.google.com/github/Norod/my-colab-experiments/blob/master/EvgenyKashin_Animal_conditional_generation.ipynb](https://colab.research.google.com/github/Norod/my-colab-experiments/blob/master/EvgenyKashin_Animal_conditional_generation.ipynb#scrollTo=reWnxuHwfTTR) (animal morph, for model trained with labels)

[https://colab.research.google.com/gist/zsyzzsoft/5fbb71b9bf9a3217576bebae5de46fc2/data-efficient-gans.ipynb](https://colab.research.google.com/gist/zsyzzsoft/5fbb71b9bf9a3217576bebae5de46fc2/data-efficient-gans.ipynb) (diffaugment; training with very small data)

[https://colab.research.google.com/drive/1tputbmA9EaXs9HL9iO21g7xN7jz_Xrko](https://colab.research.google.com/drive/1tputbmA9EaXs9HL9iO21g7xN7jz_Xrko) (layer blending)

[https://colab.research.google.com/drive/1s2XPNMwf6HDhrJ1FMwlW1jl-eQ2-_tlk](https://colab.research.google.com/drive/1s2XPNMwf6HDhrJ1FMwlW1jl-eQ2-_tlk) (toonify yourself)

[https://colab.research.google.com/github/halcy/AnimeFaceNotebooks/blob/master/colab/Stylegan2_Playground.ipynb](https://colab.research.google.com/github/halcy/AnimeFaceNotebooks/blob/master/colab/Stylegan2_Playground.ipynb) (anime)

[https://colab.research.google.com/github/dvschultz/ml-art-colabs/blob/master/SWA_playground_SG2ADA.ipynb](https://colab.research.google.com/github/dvschultz/ml-art-colabs/blob/master/SWA_playground_SG2ADA.ipynb)

[https://colab.research.google.com/github/Hephyrius/Stylegan2-Ada-Google-Colab-Starter-Notebook/blob/main/Stylegan2_Ada_Colab_Starter.ipynb](https://colab.research.google.com/github/Hephyrius/Stylegan2-Ada-Google-Colab-Starter-Notebook/blob/main/Stylegan2_Ada_Colab_Starter.ipynb)

[https://colab.research.google.com/github/eps696/stylegan2/blob/master/StyleGAN2_colab.ipynb](https://colab.research.google.com/github/eps696/stylegan2/blob/master/StyleGAN2_colab.ipynb)

[https://colab.research.google.com/github/eps696/stylegan2ada/blob/master/StyleGAN2a_colab.ipynb](https://colab.research.google.com/github/eps696/stylegan2ada/blob/master/StyleGAN2a_colab.ipynb)

[https://colab.research.google.com/github/tg-bomze/BabyGAN/blob/master/BabyGAN_(ENG).ipynb](https://colab.research.google.com/github/tg-bomze/BabyGAN/blob/master/BabyGAN_(ENG).ipynb)

  

[https://colab.research.google.com/github/davidbau/rewriting/blob/master/notebooks/rewriting-interface.ipynb](https://colab.research.google.com/github/davidbau/rewriting/blob/master/notebooks/rewriting-interface.ipynb) (network rewriting)

[https://colab.research.google.com/drive/1RGzHLEINqylBo_b8NwUqFyNDOODgSGEt](https://colab.research.google.com/drive/1RGzHLEINqylBo_b8NwUqFyNDOODgSGEt) (editing latent direction)

[https://colab.research.google.com/github/genforce/sefa/blob/master/docs/SeFa.ipynb](https://colab.research.google.com/github/genforce/sefa/blob/master/docs/SeFa.ipynb) (sefa latent editing)

  

Pre-trained stylegan models:

[https://github.com/justinpinkney/awesome-pretrained-stylegan](https://github.com/justinpinkney/awesome-pretrained-stylegan)

[https://github.com/justinpinkney/awesome-pretrained-stylegan2](https://github.com/justinpinkney/awesome-pretrained-stylegan2)

[https://colab.research.google.com/drive/1ytdR30L7uXLaG_4Iph331o70wZWA-bkd](https://colab.research.google.com/drive/1ytdR30L7uXLaG_4Iph331o70wZWA-bkd) (genforce; pggan+stylegan+...)

[https://colab.research.google.com/github/zaidalyafeai/gan-mosaics/blob/main/mosaic_demo.ipynb](https://colab.research.google.com/github/zaidalyafeai/gan-mosaics/blob/main/mosaic_demo.ipynb) (islam mosaics)

[https://colab.research.google.com/github/Norod/my-colab-experiments/blob/master/WikiArt_ADA_Example_Generation.ipynb](https://colab.research.google.com/github/Norod/my-colab-experiments/blob/master/WikiArt_ADA_Example_Generation.ipynb) (wikiart)

[https://colab.research.google.com/drive/1oxcJ1tbG77hlggdKd_d8h22nBcIZsLTL](https://colab.research.google.com/drive/1oxcJ1tbG77hlggdKd_d8h22nBcIZsLTL) (this anime does not exist)

[https://colab.research.google.com/drive/1Lg-noMq7DDpHcihQ8tCfNi0HKJOtfNtn](https://colab.research.google.com/drive/1Lg-noMq7DDpHcihQ8tCfNi0HKJOtfNtn) (anime editor)

[https://colab.research.google.com/github/Norod/my-colab-experiments/blob/master/MuppetFaces_SG2_ADA_Unconditional.ipynb](https://colab.research.google.com/github/Norod/my-colab-experiments/blob/master/MuppetFaces_SG2_ADA_Unconditional.ipynb) (muppets by doron adler)

[https://colab.research.google.com/github/yuval-alaluf/restyle-encoder/blob/master/notebooks/inference_playground.ipynb](https://colab.research.google.com/github/yuval-alaluf/restyle-encoder/blob/master/notebooks/inference_playground.ipynb#scrollTo=jQ31J_m7kTJ8) (e.g. toonification)

  

[https://colab.research.google.com/github/eladrich/pixel2style2pixel/blob/master/notebooks/inference_playground.ipynb](https://colab.research.google.com/github/eladrich/pixel2style2pixel/blob/master/notebooks/inference_playground.ipynb) (pixel2style2pixel)

[https://colab.research.google.com/github/omertov/encoder4editing/blob/main/notebooks/inference_playground.ipynb](https://colab.research.google.com/github/omertov/encoder4editing/blob/main/notebooks/inference_playground.ipynb) (fast stylegan encoder and editing)

[https://colab.research.google.com/github/yuval-alaluf/SAM/blob/master/notebooks/inference_playground.ipynb](https://colab.research.google.com/github/yuval-alaluf/SAM/blob/master/notebooks/inference_playground.ipynb) (SAM age transformation)

[https://colab.research.google.com/github/yuval-alaluf/SAM/blob/master/notebooks/animation_inference_playground.ipynb](https://colab.research.google.com/github/yuval-alaluf/SAM/blob/master/notebooks/animation_inference_playground.ipynb) (SAM age transformation)

  

Taming transformers: Landscape generation, faces

[https://colab.research.google.com/github/CompVis/taming-transformers/blob/master/scripts/taming-transformers.ipynb](https://colab.research.google.com/github/CompVis/taming-transformers/blob/master/scripts/taming-transformers.ipynb) 

  

Penis generator (NSFW)

[https://colab.research.google.com/drive/1DoCxr2pYlxCRv6RmITtFWahVXsbTexYp](https://colab.research.google.com/drive/1DoCxr2pYlxCRv6RmITtFWahVXsbTexYp)

[https://colab.research.google.com/drive/1-SDjR6ztiExBRmf5xzspNsA5t8y3kEXk](https://colab.research.google.com/drive/1-SDjR6ztiExBRmf5xzspNsA5t8y3kEXk)

  

Keras face toolbox (landmarks, parsing segmentation including hair, iris, face verification, gender, age:

[https://colab.research.google.com/github/eyaler/face_toolbox_keras/blob/master/demo.ipynb](https://colab.research.google.com/github/eyaler/face_toolbox_keras/blob/master/demo.ipynb)

  
  

Age transformation:

[https://colab.research.google.com/github/royorel/Lifespan_Age_Transformation_Synthesis/blob/master/LATS_demo.ipynb](https://colab.research.google.com/github/royorel/Lifespan_Age_Transformation_Synthesis/blob/master/LATS_demo.ipynb)

  

3d human reconstruction and motion capture

[https://colab.research.google.com/drive/11z58bl3meSzo6kFqkahMa35G5jmh2Wgt](https://colab.research.google.com/drive/11z58bl3meSzo6kFqkahMa35G5jmh2Wgt) (PIFuHD)

[https://colab.research.google.com/github/cedro3/others/blob/master/PIFuHD_Demo.ipynb](https://colab.research.google.com/github/cedro3/others/blob/master/PIFuHD_Demo.ipynb) (pifuhd)

[https://colab.research.google.com/drive/15qA6kbyVK--8q88FHXdzwPiGT0UyKvwg](https://colab.research.google.com/drive/15qA6kbyVK--8q88FHXdzwPiGT0UyKvwg) (frankmocap)

  

Green screen

[https://colab.research.google.com/github/OPHoperHPO/image-background-remove-tool/blob/master/docs/other/try.ipynb](https://colab.research.google.com/github/OPHoperHPO/image-background-remove-tool/blob/master/docs/other/try.ipynb)

[https://colab.research.google.com/drive/1cTxFq1YuoJ5QPqaTcnskwlHDolnjBkB9](https://colab.research.google.com/drive/1cTxFq1YuoJ5QPqaTcnskwlHDolnjBkB9?usp=sharing)  (requires clean background image)

[https://colab.research.google.com/drive/1Y9zWfULc8-DDTSsCH-pX6Utw8skiJG5](https://colab.research.google.com/drive/1Y9zWfULc8-DDTSsCH-pX6Utw8skiJG5s) (requires clean background image)[s](https://colab.research.google.com/drive/1Y9zWfULc8-DDTSsCH-pX6Utw8skiJG5s)

[https://colab.research.google.com/drive/1EaQ5h4u9Q_MmDSFTDmFG0ZOeSsFuRTsJ](https://colab.research.google.com/drive/1EaQ5h4u9Q_MmDSFTDmFG0ZOeSsFuRTsJ?usp=sharing) (Animal matting)

[https://colab.research.google.com/drive/1Ut2szLBTxPejGHt_GYUkua21yUVWseOE](https://colab.research.google.com/drive/1Ut2szLBTxPejGHt_GYUkua21yUVWseOE) (FBA matting)

[https://colab.research.google.com/drive/1-BqXD3EzDY6PHRdwb3cWayk2KictbFaz?usp=sharin  g](https://colab.research.google.com/drive/1-BqXD3EzDY6PHRdwb3cWayk2KictbFaz?usp=sharing) (sky replacement )

[j.mp/vid2green](https://vid2green) (video; u2net+modnet+portrait generation)

[https://github.com/danielgatis/rembg](https://github.com/danielgatis/rembg) (u2net)

[https://github.com/ecsplendid/rembg-greenscreen](https://github.com/ecsplendid/rembg-greenscreen) (u2net video)

[https://colab.research.google.com/github/shreyas-bk/U-2-Net-Demo/blob/master/DEMOS/U_2_Netp_Demonstration_Colab.ipynb](https://colab.research.google.com/github/shreyas-bk/U-2-Net-Demo/blob/master/DEMOS/U_2_Netp_Demonstration_Colab.ipynb) (u2net-p)

[https://colab.research.google.com/github/Norod/my-colab-experiments/blob/master/U_2_Netp_Cropper_Colab.ipynb](https://colab.research.google.com/github/Norod/my-colab-experiments/blob/master/U_2_Netp_Cropper_Colab.ipynb) (u2net-p)

[https://www.gradio.app/hub/aliabd/modnet](https://www.gradio.app/hub/aliabd/modnet)

[https://gradio.app/hub/AK391/U-2-Net](https://gradio.app/hub/AK391/U-2-Net)

[https://colab.research.google.com/drive/1GANpbKT06aEFiW-Ssx0DQnnEADcXwQG6](https://colab.research.google.com/drive/1GANpbKT06aEFiW-Ssx0DQnnEADcXwQG6) (modnet)

[https://colab.research.google.com/drive/1Pt3KDSc2q7WxFvekCnCLD8P0gBEbxm6J](https://colab.research.google.com/drive/1Pt3KDSc2q7WxFvekCnCLD8P0gBEbxm6J) (modnet -  webcam)

[https://colab.research.google.com/drive/10z-pNKRnVNsp0Lq9tH1J_XPZ7CBC_uHm](https://colab.research.google.com/drive/10z-pNKRnVNsp0Lq9tH1J_XPZ7CBC_uHm) (RVM)

  

Image to sketch:

[https://face-lol.github.io/](https://face-lol.github.io/) (APdrawingGAN)

[https://colab.research.google.com/github/vijishmadhavan/Light-Up/blob/master/ArtLine(AR).ipynb](https://colab.research.google.com/github/vijishmadhavan/Light-Up/blob/master/ArtLine(AR).ipynb) (quality)

[https://colab.research.google.com/github/vijishmadhavan/Light-Up/blob/master/ArtLine.ipynb](https://colab.research.google.com/github/vijishmadhavan/Light-Up/blob/master/ArtLine.ipynb) (smooth)

[https://colab.research.google.com/github/cedro3/others/blob/master/ArtLine_make_gif.ipynb](https://colab.research.google.com/github/cedro3/others/blob/master/ArtLine_make_gif.ipynb) (artline video to gif)

[https://colab.research.google.com/github/vijishmadhavan/Light-Up/blob/master/Toon_Me_(Alt_Model).ipynb](https://colab.research.google.com/github/vijishmadhavan/Light-Up/blob/master/Toon_Me_(Alt_Model).ipynb)

[https://colab.research.google.com/github/vijishmadhavan/Light-Up/blob/master/Toon_Me_(Try_it_on_Colab).ipynb](https://colab.research.google.com/github/vijishmadhavan/Light-Up/blob/master/Toon_Me_(Try_it_on_Colab).ipynb)

[j.mp/vid2green](https://vid2green) (u2net + video + blend)

[https://toonme.com/](https://toonme.com/)

[https://toonme.com/labs](https://toonme.com/labs)

[http://profu.ai/](http://profu.ai/)

  
  
  

Deep fakes:

[https://colab.research.google.com/github/chervonij/DFL-Colab/blob/master/DFL_Colab.ipynb](https://colab.research.google.com/github/chervonij/DFL-Colab/blob/master/DFL_Colab.ipynb)

[https://colab.research.google.com/github/AliaksandrSiarohin/motion-cosegmentation/blob/master/part_swap.ipynb](https://colab.research.google.com/github/AliaksandrSiarohin/motion-cosegmentation/blob/master/part_swap.ipynb)

[terryky.github.io/tfjs_webgl_app/face_landmark](https://terryky.github.io/tfjs_webgl_app/face_landmark) (face swap from webcam)

[https://j.mp/facemesh](https://j.mp/facemesh) (face swap from webcam or video)

[https://colab.research.google.com/github/neuralchen/SimSwap/blob/main/SimSwap%20colab.ipynb](https://colab.research.google.com/github/neuralchen/SimSwap/blob/main/SimSwap%20colab.ipynb)

[https://colab.research.google.com/github/neuralchen/SimSwap/blob/main/MultiSpecific.ipynb](https://colab.research.google.com/github/neuralchen/SimSwap/blob/main/MultiSpecific.ipynb)

[https://github.com/tg-bomze/collection-of-notebooks/blob/master/Simple_Face_Swapper.ipynb](https://github.com/tg-bomze/collection-of-notebooks/blob/master/Simple_Face_Swapper.ipynb)

[https://colab.research.google.com/github/tg-bomze/collection-of-notebooks/blob/master/QuickFaceSwap.ipynb](https://colab.research.google.com/github/tg-bomze/collection-of-notebooks/blob/master/QuickFaceSwap.ipynb#scrollTo=BUin8V0vAirE)

  
  

Single image head avatars:

[https://colab.research.google.com/github/AliaksandrSiarohin/first-order-model/blob/master/demo.ipynb](https://colab.research.google.com/github/AliaksandrSiarohin/first-order-model/blob/master/demo.ipynb) (head reenactment with new GUI - fomm)

[https://github.com/alievk/avatarify/wiki/Windows-App-(Beta)](https://github.com/alievk/avatarify/wiki/Windows-App-(Beta)) 

[https://j.mp/vid2head](https://j.mp/vid2head) (head reenactment from video - fomm)

[https://j.mp/cam2head](https://j.mp/cam2head) (live head reenactment from webcam)

[https://www.myheritage.co.il/deep-nostalgia](https://www.myheritage.co.il/deep-nostalgia)

Full body puppeteering:

[https://j.mp/vid2body](https://j.mp/vid2body) (full body reenactment from video - fomm)

[https://colab.research.google.com/github/svip-lab/impersonator/blob/master/impersonator.ipynb](https://colab.research.google.com/github/svip-lab/impersonator/blob/master/impersonator.ipynb)

[https://j.mp/vid2act](https://j.mp/vid2act) (full body reenactment from video - impersonator)

[colab.research.google.com/drive/1bwUnj-9NnJA2EMr7eWO4I45UuBtKud_](http://colab.research.google.com/drive/1bwUnj-9NnJA2EMr7eWO4I45UuBtKudg_) (impersonator++)

[https://j.mp/vid2warp](https://j.mp/vid2warp) (full body from video - impersonator++)

[https://github.com/iPERDance/iPERCore/wiki/How-to-use-the-released-version-on-windows%3F](https://github.com/iPERDance/iPERCore/wiki/How-to-use-the-released-version-on-windows%3F) (impersonator++ windows app)

[pose-animator-demo.firebaseapp.com/camera.html](https://pose-animator-demo.firebaseapp.com/camera.html)

[https://colab.research.google.com/github/AliaksandrSiarohin/articulated-animation/blob/main/demo.ipynb](https://colab.research.google.com/github/AliaksandrSiarohin/articulated-animation/blob/main/demo.ipynb)

[https://j.mp/mraa-body](https://j.mp/mraa-body) (full body from video - articulated animation) 

  

Wav2lip / make it talk

[https://colab.research.google.com/github/yzhou359/MakeItTalk/blob/main/quick_demo.ipynb](https://colab.research.google.com/github/yzhou359/MakeItTalk/blob/main/quick_demo.ipynb)

[https://colab.research.google.com/github/yzhou359/MakeItTalk/blob/main/quick_demo_tdlr.ipynb](https://colab.research.google.com/github/yzhou359/MakeItTalk/blob/main/quick_demo_tdlr.ipynb)

  

[https://bhaasha.iiit.ac.in/lipsync/](https://bhaasha.iiit.ac.in/lipsync/)

[https://colab.research.google.com/drive/1tZpDWXz49W6wDcTprANRGLo2D_EbD5J8](https://colab.research.google.com/drive/1tZpDWXz49W6wDcTprANRGLo2D_EbD5J8)

[j.mp/wav2lip](https://j.mp/wav2lip)

[https://j.mp/wav2lip](https://colab.research.google.com/github/eyaler/avatars4all/blob/master/melaflefon.ipynb) (lip syncing - animating lips in image or video from audio, optionally switching between speakers)

[https://vo.codes](https://vo.codes) (also has wav2lip interface)

  

Anime manipulation

[https://colab.research.google.com/github/pkhungurn/talking-head-anime-demo/blob/master/tha_colab.ipynb](https://colab.research.google.com/github/pkhungurn/talking-head-anime-demo/blob/master/tha_colab.ipynb)

[https://colab.research.google.com/github/pkhungurn/talking-head-anime-2-demo/blob/master/colab.ipynb](https://colab.research.google.com/github/pkhungurn/talking-head-anime-2-demo/blob/master/colab.ipynb)

  

Speech synthesis with celebrity voices

[https://vo.codes](https://vo.codes) (also has wav2lip interface)

  

Text to speech comparing different models: [https://colab.research.google.com/github/NVIDIA/NeMo/blob/stable/tutorials/tts/1_TTS_inference.ipynb](https://colab.research.google.com/github/NVIDIA/NeMo/blob/stable/tutorials/tts/1_TTS_inference.ipynb)

Controllable talknet (e.g. mimic cartoon voices): [https://colab.research.google.com/drive/1aj6Jk8cpRw7SsN3JSYCv57CrR6s0gYPB](https://colab.research.google.com/drive/1aj6Jk8cpRw7SsN3JSYCv57CrR6s0gYPB)

  
  

Image generation and animation based on a single image

[https://colab.research.google.com/github/dvschultz/ai/blob/master/SinGAN.ipynb](https://colab.research.google.com/github/dvschultz/ai/blob/master/SinGAN.ipynb)

  

Deepnude

[https://colab.research.google.com/gist/Ptibouc77/cd7da30a967b301f2d7a042ad6f06886/dreampower-v1-2-8-updated-from-1-2-5-from-firstdee.ipynb](https://colab.research.google.com/gist/Ptibouc77/cd7da30a967b301f2d7a042ad6f06886/dreampower-v1-2-8-updated-from-1-2-5-from-firstdee.ipynb)

[https://colab.research.google.com/gist/FirstDee/c3a94ff37e0561e597b65160aabbbc07/dreamtime-v1.ipynb](https://colab.research.google.com/gist/FirstDee/c3a94ff37e0561e597b65160aabbbc07/dreamtime-v1.ipynb)

  
  

3d 

[https://colab.research.google.com/drive/1706ToQrkIZshRSJSHvZ1RuCiM__YX3Bz](https://colab.research.google.com/drive/1706ToQrkIZshRSJSHvZ1RuCiM__YX3Bz)

[https://colab.research.google.com/drive/1FcQibnjfp4mpn_WJiQlVBRJMkhSMZqbU](https://colab.research.google.com/drive/1FcQibnjfp4mpn_WJiQlVBRJMkhSMZqbU)

[https://colab.research.google.com/gist/asears/67bdf99b4d88edd56f512242b46708b7/3d-photo-inpainting-args.ipynb](https://colab.research.google.com/gist/asears/67bdf99b4d88edd56f512242b46708b7/3d-photo-inpainting-args.ipynb#scrollTo=5o-EIMeaghU0)

[https://colab.research.google.com/drive/1iT5PfK7zl1quAOwC227GfBjieFMVHjI5](https://colab.research.google.com/drive/1iT5PfK7zl1quAOwC227GfBjieFMVHjI5) (semantic view synthesis)

  

Face depixelizer (pulse)

[https://colab.research.google.com/github/ctawong/PULSE_from_image_url/blob/master/PULSE_URL.ipynb](https://colab.research.google.com/github/ctawong/PULSE_from_image_url/blob/master/PULSE_URL.ipynb)

  
  

Feature visualization:

[https://github.com/tensorflow/lucid](https://github.com/tensorflow/lucid)

  

Pix2Pix:

[https://affinelayer.com/pixsrv/](https://affinelayer.com/pixsrv/)

[https://zaidalyafeai.github.io/pix2pix/scene.html](https://zaidalyafeai.github.io/pix2pix/scene.html)

[https://zaidalyafeai.github.io/webcam-reconstruction/](https://zaidalyafeai.github.io/webcam-reconstruction/)

[https://colab.research.google.com/github/zaidalyafeai/Notebooks/blob/master/tf_pix2pix.ipynb](https://colab.research.google.com/github/zaidalyafeai/Notebooks/blob/master/tf_pix2pix.ipynb)

[https://www.kaggle.com/norod78/sketch2pokemon-iterative-trainer](https://www.kaggle.com/norod78/sketch2pokemon-iterative-trainer)

  

BigGAN:

[http://artbreeder.com/](http://artbreeder.com/)

[https://colab.research.google.com/github/tensorflow/hub/blob/master/examples/colab/biggan_generation_with_tf_hub.ipynb](https://colab.research.google.com/github/tensorflow/hub/blob/master/examples/colab/biggan_generation_with_tf_hub.ipynb)

[https://colab.research.google.com/drive/1MhfEAOBwhGu1A-F2NSVxGQrkJ4vk7w4V](https://colab.research.google.com/drive/1MhfEAOBwhGu1A-F2NSVxGQrkJ4vk7w4V)

[https://colab.research.google.com/github/zaidalyafeai/Notebooks/blob/master/BigGAN.ipynb](https://colab.research.google.com/github/zaidalyafeai/Notebooks/blob/master/BigGAN.ipynb)

[https://colab.research.google.com/github/zaidalyafeai/Notebooks/blob/master/BigGanEx.ipynb](https://colab.research.google.com/github/zaidalyafeai/Notebooks/blob/master/BigGanEx.ipynb)

[https://colab.research.google.com/drive/1rqDwIddy0eunhhV8yrznG4SNiB5XWFJJ](https://colab.research.google.com/drive/1rqDwIddy0eunhhV8yrznG4SNiB5XWFJJ)

[https://colab.research.google.com/github/HighCWu/anime_biggan_toy/blob/main/colab/Play_Anime_BigGAN.ipynb](https://colab.research.google.com/github/HighCWu/anime_biggan_toy/blob/main/colab/Play_Anime_BigGAN.ipynb) (anime)

  

Bigbigan (bigan encoder)

[https://colab.research.google.com/github/tensorflow/hub/blob/master/examples/colab/bigbigan_with_tf_hub.ipynb](https://colab.research.google.com/github/tensorflow/hub/blob/master/examples/colab/bigbigan_with_tf_hub.ipynb)

  

SIREN/FFT/Implicit 

[https://colab.research.google.com/github/vsitzmann/siren/blob/master/explore_siren.ipynb](https://colab.research.google.com/github/vsitzmann/siren/blob/master/explore_siren.ipynb)

[https://colab.research.google.com/drive/1HSsQen6lXnPHEpQPzmCuD5zFKhtPdZAI](https://colab.research.google.com/drive/1HSsQen6lXnPHEpQPzmCuD5zFKhtPdZAI#scrollTo=3wCS6y_o0zw6) (image/video)

[https://colab.research.google.com/github/tancik/fourier-feature-networks/blob/master/Demo.ipynb](https://colab.research.google.com/github/tancik/fourier-feature-networks/blob/master/Demo.ipynb)

[https://colab.research.google.com/github/tancik/learnit/blob/master/meta_demo.ipynb](https://colab.research.google.com/github/tancik/learnit/blob/master/meta_demo.ipynb)

  
  

CLIP zero shot image classification / object detection

[https://colab.research.google.com/github/openai/CLIP/blob/main/notebooks/Interacting_with_CLIP.ipynb](https://colab.research.google.com/github/openai/CLIP/blob/main/notebooks/Interacting_with_CLIP.ipynb)

[https://colab.research.google.com/drive/1LXla2q9MCRRI_kTjpvag2Vz-7EGLnki5](https://colab.research.google.com/drive/1LXla2q9MCRRI_kTjpvag2Vz-7EGLnki5#scrollTo=lOF3Feb7jrnu) (broken?)

[https://colab.research.google.com/github/kevinzakka/clip_playground/blob/main/CLIP_Zero_shot_Detector.ipynb](https://colab.research.google.com/github/kevinzakka/clip_playground/blob/main/CLIP_Zero_shot_Detector.ipynb)

[https://colab.research.google.com/github/kevinzakka/clip_playground/blob/main/CLIP_Patch_Detection.ipynb](https://colab.research.google.com/github/kevinzakka/clip_playground/blob/main/CLIP_Patch_Detection.ipynb)

[https://colab.research.google.com/drive/1273xNBDcbc4XGjJnnB3V8YoYU9aIcBIB](https://colab.research.google.com/drive/1273xNBDcbc4XGjJnnB3V8YoYU9aIcBIB?usp=sharing)

  
  
  
  

CLIP

[https://colab.research.google.com/drive/1FoHdqoqKntliaQKnMoNs3yn5EALqWtvP](https://colab.research.google.com/drive/1FoHdqoqKntliaQKnMoNs3yn5EALqWtvP) (siren + clip)

[https://colab.research.google.com/drive/1K1vfpTEvAmxW2rnhAaALRVyis8EiLOnD](https://colab.research.google.com/drive/1K1vfpTEvAmxW2rnhAaALRVyis8EiLOnD?usp=sharing) (siren + clip)

[https://colab.research.google.com/drive/1NCceX2mbiKOSlAd_o7IU7nA9UskKN5WR](https://colab.research.google.com/drive/1NCceX2mbiKOSlAd_o7IU7nA9UskKN5WR) (biggan + clip)

[https://colab.research.google.com/github/tg-bomze/collection-of-notebooks/blob/master/Text2Image_v2.ipynb](https://colab.research.google.com/github/tg-bomze/collection-of-notebooks/blob/master/Text2Image_v2.ipynb) (biggan + clip)

[https://colab.research.google.com/drive/1MEWKbm-driRNF8PrU7ogS5o3se-ePyPb](https://colab.research.google.com/drive/1MEWKbm-driRNF8PrU7ogS5o3se-ePyPb) (biggan+clip using big-sleep library)

[https://colab.research.google.com/drive/1jF8pyZ7uaNYbk9ZiVdxTOajkp8kbmkLK](https://colab.research.google.com/drive/1jF8pyZ7uaNYbk9ZiVdxTOajkp8kbmkLK) (biggan+clip story hallucinator)

[j.mp/bigclip](https://j.mp/bigclip) (biggan + clip)

[j.mp/wanderclip](https://j.mp/bigclip) (biggan + clip + cma-es)

[https://colab.research.google.com/github/nagolinc/notebooks/blob/main/TADNE_and_CLIP.ipynb](https://colab.research.google.com/github/nagolinc/notebooks/blob/main/TADNE_and_CLIP.ipynb) (stylegan2-ada anime+clip)

[https://colab.research.google.com/github/nagolinc/notebooks/blob/main/CLIP_%2B_TADNE_(pytorch)_v2.ipynb](https://colab.research.google.com/github/nagolinc/notebooks/blob/main/CLIP_%2B_TADNE_(pytorch)_v2.ipynb) (stylegan2-ada anime+clip)

[https://colab.research.google.com/github/orpatashnik/StyleCLIP/blob/main/notebooks/optimization_playground.ipynb](https://colab.research.google.com/github/orpatashnik/StyleCLIP/blob/main/notebooks/optimization_playground.ipynb)CLIP + TADNE (pytorch) v2 - Colaboratoryhttps://colab.research.google.com/github/nagolinc/notebooks/blob/main/CLIP_%2B_TADNE_(pytorch)_v2.ipynb

[https://colab.research.google.com/github/orpatashnik/StyleCLIP/blob/main/notebooks/StyleCLIP_global.ipynb](https://colab.research.google.com/github/orpatashnik/StyleCLIP/blob/main/notebooks/StyleCLIP_global.ipynb)

[https://colab.research.google.com/github/orpatashnik/StyleCLIP/blob/main/notebooks/mapper_playground.ipynb](https://colab.research.google.com/github/orpatashnik/StyleCLIP/blob/main/notebooks/mapper_playground.ipynb)

[https://colab.research.google.com/github/bycloudai/StyleCLIP-e4e-colab/blob/main/notebooks/e4e%2BStyleCLIPglobal.ipynb](https://colab.research.google.com/github/bycloudai/StyleCLIP-e4e-colab/blob/main/notebooks/e4e%2BStyleCLIPglobal.ipynb)

[https://www.reddit.com/r/MachineLearning/comments/ldc6oc/p_list_of_sitesprogramsprojects_that_use_openais/](https://www.reddit.com/r/MachineLearning/comments/ldc6oc/p_list_of_sitesprogramsprojects_that_use_openais/)

[https://colab.research.google.com/github/eyaler/VectorAscent/blob/master/VectorAscent.ipynb](https://colab.research.google.com/github/eyaler/VectorAscent/blob/master/VectorAscent.ipynb) (svg)

[https://huggingface.co/spaces/akhaliq/VQGAN_CLIP](https://huggingface.co/spaces/akhaliq/VQGAN_CLIP)

[https://colab.research.google.com/github/rinongal/stylegan-nada/blob/main/stylegan_nada.ipynb](https://colab.research.google.com/github/rinongal/stylegan-nada/blob/main/stylegan_nada.ipynb)

[https://bit.ly/txt2im](https://bit.ly/txt2im) (CompVis Latent Diffusion Models)

  
  

CLIP based style analogies (see e.g. - [https://twitter.com/RiversHaveWings/status/1478719186125811715](https://twitter.com/RiversHaveWings/status/1478719186125811715)):

[https://colab.research.google.com/drive/19M9RFEgCmCVAF-h2KuNmPwgftPi_ZEp3](https://colab.research.google.com/drive/19M9RFEgCmCVAF-h2KuNmPwgftPi_ZEp3)

[https://colab.research.google.com/drive/17AqhaKLZmmUA27aNSc6fJYMR9uypeIci](https://colab.research.google.com/drive/17AqhaKLZmmUA27aNSc6fJYMR9uypeIci)

  

rudalle Text2Image (malevich v3 + emojich):

[https://colab.research.google.com/github/Norod/my-colab-experiments/blob/master/Simple_ruDALLE_inference_%5Bsupports_v1_0_0%5D.ipynb](https://colab.research.google.com/github/Norod/my-colab-experiments/blob/master/Simple_ruDALLE_inference_%5Bsupports_v1_0_0%5D.ipynb#scrollTo=GdOYJvwZSB-D)

  

ruDalle Outpainting:

[https://j.mp/outpaint](https://j.mp/outpaint)

  

rudolph:

[https://colab.research.google.com/drive/1gmTDA13u709OXiAeXWGm7sPixRhEJCga](https://colab.research.google.com/drive/1gmTDA13u709OXiAeXWGm7sPixRhEJCga?usp=sharing#scrollTo=kU6XrbwxA3zt)

  

Spade/Gaugan:

[http://nvidia-research-mingyuliu.com/gaugan/](http://nvidia-research-mingyuliu.com/gaugan/) 

[http://gaugan.org/gaugan2/](http://gaugan.org/gaugan2/)

[https://www.nvidia.com/en-us/studio/canvas/](https://www.nvidia.com/en-us/studio/canvas/)

  
  

animeGAN (video2anime): [https://colab.research.google.com/github/tg-bomze/Video2Anime/blob/master/AnimeGan_Video_(Eng).ipynb](https://colab.research.google.com/github/tg-bomze/Video2Anime/blob/master/AnimeGan_Video_(Eng).ipynb)

[https://animegan.js.org/](https://animegan.js.org/) (web demo for images)

[https://colab.research.google.com/github/mchong6/GANsNRoses/blob/main/inference_colab.ipynb](https://colab.research.google.com/github/mchong6/GANsNRoses/blob/main/inference_colab.ipynb)

[https://gradio.app/hub/AK391/GANsNRoses](https://gradio.app/hub/AK391/GANsNRoses)

  
  

Audio style transfer:

[https://sites.research.google/tonetransfer](https://sites.research.google/tonetransfer)

[https://colab.research.google.com/github/cifkao/ss-vq-vae/blob/main/experiments/colab_demo.ip ynb](https://colab.research.google.com/github/cifkao/ss-vq-vae/blob/main/experiments/colab_demo.ipynb) (timbre)

  

Word2Dream: [https://eyalgruss.com/word2dream](https://eyalgruss.com/word2dream)

  
  
  
  

  

Text generation

[https://www.robinsloan.com/voyages-in-sentence-space/](https://www.robinsloan.com/voyages-in-sentence-space/) (sentence interpolation)

[https://cs.stanford.edu/people/karpathy/recurrentjs/](https://cs.stanford.edu/people/karpathy/recurrentjs/)

[https://www.thisstorydoesnotexist.com/](https://www.thisstorydoesnotexist.com/)

[https://gpt2.apps.allenai.org](https://gpt2.apps.allenai.org)

[https://www.askskynet.com/](https://www.askskynet.com/)

[https://colab.research.google.com/github/blade1780/bert/blob/master/Gpt-2.ipynb](https://colab.research.google.com/github/blade1780/bert/blob/master/Gpt-2.ipynb)

[https://colab.research.google.com/github/ilopezfr/gpt-2/blob/master/gpt-2-playground_.ipynb](https://colab.research.google.com/github/ilopezfr/gpt-2/blob/master/gpt-2-playground_.ipynb#scrollTo=Xfskdff44QlD)

[https://colab.research.google.com/drive/1da54684tFMjPbR5idbvoCyjOoEGwIVwV](https://colab.research.google.com/drive/1da54684tFMjPbR5idbvoCyjOoEGwIVwV)

[https://colab.research.google.com/drive/1VLG8e7YSEwypxU-noRNhsv5dW4NfTGce](https://colab.research.google.com/drive/1VLG8e7YSEwypxU-noRNhsv5dW4NfTGce) (including larger 345MB model)

[https://talktotransformer.com/](https://talktotransformer.com/) (1.5GB model)

[https://transformer.huggingface.co/](https://transformer.huggingface.co/)

[https://www.ai21.com/haim](https://www.ai21.com/haim) (conditional on suffix and number of words)

[https://colab.research.google.com/drive/1hVveBQShDru1Mjnhe4C21uQv4A2eH1tV](https://colab.research.google.com/drive/1hVveBQShDru1Mjnhe4C21uQv4A2eH1tV) (ctrl)

[https://colab.research.google.com/drive/1nDh3ayRPJGK5ciPO2D3TFkYZFqclBWHY](https://colab.research.google.com/drive/1nDh3ayRPJGK5ciPO2D3TFkYZFqclBWHY) (ctrl)

[https://askgpt.com/](https://askgpt.com/)

[https://colab.research.google.com/github/google/trax/blob/master/trax/models/reformer/text_generation.ipynb](https://colab.research.google.com/github/google/trax/blob/master/trax/models/reformer/text_generation.ipynb) (reformer with TPU training)

[https://github.com/karpathy/minGPT/blob/master/play_char.ipynb](https://github.com/karpathy/minGPT/blob/master/play_char.ipynb) (train minimal char gpt)

[https://colab.research.google.com/github/EleutherAI/GPTNeo/blob/master/GPTNeo_example_notebook.ipynb](https://colab.research.google.com/github/EleutherAI/GPTNeo/blob/master/GPTNeo_example_notebook.ipynb)

[https://colab.research.google.com/github/EleutherAI/gpt-neo/blob/24aeaf9ef834884f590b0899c104793914bd6b31/GPTNeo_example_notebook.ipynb](https://colab.research.google.com/github/EleutherAI/gpt-neo/blob/24aeaf9ef834884f590b0899c104793914bd6b31/GPTNeo_example_notebook.ipynb) (community trained - requires large cloud storage)

[https://colab.research.google.com/github/huggingface/blog/blob/master/notebooks/02_how_to_generate.ipynb](https://colab.research.google.com/github/huggingface/blog/blob/master/notebooks/02_how_to_generate.ipynb)

  

Hebrew generation!

[https://colab.research.google.com/github/Norod/hebrew-gpt_neo/blob/main/hebrew_gpt_neo_with_Javascript_interfaceipynb.ipynb](https://colab.research.google.com/github/Norod/hebrew-gpt_neo/blob/main/hebrew_gpt_neo_with_Javascript_interfaceipynb.ipynb?fbclid=IwAR2FOTGGM-vQDCIWKQTc_pGTx1Asjb7y4imoDwxo5yRdtawIkzhQRXeMWHg)

[https://stage.e-gayon.com](https://stage.e-gayon.com)

[https://e-gayon.com/](https://e-gayon.com/)

[https://github.com/CiTRuS93/McNLP/blob/main/McNLP-build.ipynb](https://github.com/CiTRuS93/McNLP/blob/main/McNLP-build.ipynb) (hebrew rap!)

[j.mp/bertdemo](http://j.mp/bertdemo) - bert + hebrew + shirbert = hebrew poetry glitcher

  

Image captioning:

[https://colab.research.google.com/github/saahiluppal/catr/blob/master/catr_demo.ipynb](https://colab.research.google.com/github/saahiluppal/catr/blob/master/catr_demo.ipynb)

[https://colab.research.google.com/drive/1tuoAC5F4sC7qid56Z0ap-stR3rwdk0ZV](https://colab.research.google.com/drive/1tuoAC5F4sC7qid56Z0ap-stR3rwdk0ZV) (clip prefix captioning)

  

Gpt2 for image generation:

[https://colab.research.google.com/drive/1c1kmO9tixviyBB7IGh-jVpLvOh2RpLYk](https://colab.research.google.com/drive/1c1kmO9tixviyBB7IGh-jVpLvOh2RpLYk)

[https://colab.research.google.com/drive/1qgt8cSwKF957PgPTKhRcNwDIfWrMhbV9](https://colab.research.google.com/drive/1qgt8cSwKF957PgPTKhRcNwDIfWrMhbV9)

[https://colab.research.google.com/drive/1neFtD1y3RyPdZzfY7nRwzCpMcytHdNcw](https://colab.research.google.com/drive/1neFtD1y3RyPdZzfY7nRwzCpMcytHdNcw)

[https://colab.research.google.com/drive/1em6hc60VpwfKfBMYDVP8zgzanA9tUVaS](https://colab.research.google.com/drive/1em6hc60VpwfKfBMYDVP8zgzanA9tUVaS)

  
  
  

Pose:

[https://googlecreativelab.github.io/posenet-sketchbook/](https://googlecreativelab.github.io/posenet-sketchbook/)

[https://colab.research.google.com/github/tugstugi/dl-colab-notebooks/blob/master/notebooks/OpenPose.ipynb](https://colab.research.google.com/github/tugstugi/dl-colab-notebooks/blob/master/notebooks/OpenPose.ipynb)

[https://pose-animator-demo.firebaseapp.com/camera.html](https://pose-animator-demo.firebaseapp.com/camera.html)

[https://colab.research.google.com/github/cedro3/others/blob/master/LSE_OpenPose.ipynb](https://colab.research.google.com/github/cedro3/others/blob/master/LSE_OpenPose.ipynb) (video)

[https://colab.research.google.com/github/cedro3/others/blob/master/VideoPose3D.ipynb](https://colab.research.google.com/github/cedro3/others/blob/master/VideoPose3D.ipynb) (video pose 3d)

[https://terryky.github.io/tfjs_webgl_app/](https://terryky.github.io/tfjs_webgl_app/) (hand, pose, face swapping and more in the browser)

[https://colab.research.google.com/drive/1uCuA6We9T5r0WljspEHWPHXCT_2bMKUy](https://colab.research.google.com/drive/1uCuA6We9T5r0WljspEHWPHXCT_2bMKUy#scrollTo=FMJBvXvw-NsF)

https://colab.research.google.com/drive/14Zgotr2_F0LfvcpRi03uQdMvUbLQSgok

  

Face and body generation-

[https://colab.research.google.com/drive/1kDMnB9IsnuWa_KFddOXC21OD8m_Hkpow](https://colab.research.google.com/drive/1kDMnB9IsnuWa_KFddOXC21OD8m_Hkpow)

  
  

Depth prediction:

[http://stereo.jpn.org/jpn/stphmkr/google/colabe.html](http://stereo.jpn.org/jpn/stphmkr/google/colabe.html)

[https://github.com/ialhashim/DenseDepth](https://github.com/ialhashim/DenseDepth)

[https://colab.research.google.com/github/p-ranav/merged_depth/blob/master/merged_depth/nets/monodepth2/depth_prediction_example.ipynb](https://colab.research.google.com/github/p-ranav/merged_depth/blob/master/merged_depth/nets/monodepth2/depth_prediction_example.ipynb)

  

Mediapipe facemesh:

[https://colab.research.google.com/drive/1FCxIsJS9i58uAsgsLFqDwFmiPO14Z2Hd](https://colab.research.google.com/drive/1FCxIsJS9i58uAsgsLFqDwFmiPO14Z2Hd)

[https://eyaler.github.io/tfjs_webgl_app/face_landmark](https://eyaler.github.io/tfjs_webgl_app/face_landmark) (face swap from camera/video)

  

Speaker separation:

[https://colab.research.google.com/github/pyannote/pyannote-audio/blob/master/notebooks/introduction_to_pyannote_audio_speaker_diarization_toolkit.ipynb](https://colab.research.google.com/github/pyannote/pyannote-audio/blob/master/notebooks/introduction_to_pyannote_audio_speaker_diarization_toolkit.ipynb)

  
  

Old school:

[http://picbreeder.org/](http://picbreeder.org/)

[https://j.mp/gmicvid](https://j.mp/gmicvid)  (GMIC filters for video)

[https://gmicol.greyc.fr/](https://gmicol.greyc.fr/) (GMIC online for images)

[https://bit.li/plotpi](https://bit.li/plotpi) (plotting pi - numberphile)

  
  

More:

[https://github.com/mmattyg/AI4D](https://github.com/mmattyg/AI4D)

[https://github.com/tugstugi/dl-colab-notebooks](https://github.com/tugstugi/dl-colab-notebooks)

[https://github.com/styler00dollar/dl-colab-notebooks](https://github.com/styler00dollar/dl-colab-notebooks)

[https://github.com/mrm8488/shared_colab_notebooks](https://github.com/mrm8488/shared_colab_notebooks)

[https://github.com/dvschultz/ml-art-colabs](https://github.com/dvschultz/ml-art-colabs)

[https://deepai.org/apis](https://deepai.org/apis)

[https://github.com/PINTO0309/PINTO_model_zoo](https://github.com/PINTO0309/PINTO_model_zoo)

[https://github.com/google/mediapipe](https://github.com/google/mediapipe)

[https://viz.mediapipe.dev/demo](https://viz.mediapipe.dev/demo)

[https://create.playform.io](https://create.playform.io/my-projects)

[https://github.com/tensorflow/docs/tree/master/site/en/tutorials/generative](https://github.com/tensorflow/docs/tree/master/site/en/tutorials/generative)

[https://github.com/DmitryUlyanov/deep-image-prior](https://github.com/DmitryUlyanov/deep-image-prior)

[https://github.com/amrzv/awesome-colab-notebookshttps://github.com/amrzv/awesome-colab-notebooks](https://github.com/amrzv/awesome-colab-notebookshttps://github.com/amrzv/awesome-colab-notebooks)

[https://colab.research.google.com/github/aicrumb/useless-pytools/blob/main/useless_py.ipynb](https://colab.research.google.com/github/aicrumb/useless-pytools/blob/main/useless_py.ipynb)

[https://github.com/Norod/my-colab-experiments](https://github.com/Norod/my-colab-experiments)

[https://github.com/tg-bomze/collection-of-notebooks](https://github.com/tg-bomze/collection-of-notebooks)

[https://docs.google.com/document/u/1/d/1ON4unvrGC2fSEAHMVb4idopPlWmzM0Lx5cxiOXG47k4/mobilebasic](https://docs.google.com/document/u/1/d/1ON4unvrGC2fSEAHMVb4idopPlWmzM0Lx5cxiOXG47k4/mobilebasic) (hitchhiker’s guide to latent space colabs)

https://pharmapsychotic.com/tools.html

  
  

Offline tools:

[https://softology.com.au/voc.htm](https://softology.com.au/voc.htm)

[https://ebsynth.com/](https://ebsynth.com/)

  

nlp:

[https://notebooks.quantumstat.com/](https://notebooks.quantumstat.com/)

***